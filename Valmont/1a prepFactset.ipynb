{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factset data needs some prep and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime  import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pandas.tseries.offsets import MonthBegin\n",
    "\n",
    "from getConfig import getConfig\n",
    "\n",
    "colMapping = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = getConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the frequency of each column\n",
    "def writeRec(colMapping):\n",
    "    with open(\"/home/tbrownex/data/Hackett/Valmont/colFrequency.csv\", \"w\") as f:\n",
    "        for x in colMapping:\n",
    "            rec = x[0]+\"|\"+x[1]+\"\\n\"\n",
    "            f.write(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Monthly first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the format of the month and sort by month\n",
    "m = pd.read_csv(config[\"dataLoc\"]+\"/Factset/MEImonthly.csv\")\n",
    "\n",
    "m[\"Date\"] = pd.to_datetime(m[\"Date\"], format='%y-%b')\n",
    "m.set_index(\"Date\", inplace=True)\n",
    "m.sort_index(inplace=True)\n",
    "\n",
    "for col in m:\n",
    "    tup = (col, \"M\")\n",
    "    colMapping.append(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the format of the month and sort by month\n",
    "q = pd.read_csv(config[\"dataLoc\"]+\"/Factset/MEIquarterly.txt\", sep=\"\\t\", thousands=r',')\n",
    "\n",
    "q[\"Date\"] = pd.to_datetime(q[\"Date\"], format='%y-%b')\n",
    "\n",
    "q.set_index(\"Date\", inplace=True)\n",
    "q.sort_index(inplace=True)\n",
    "\n",
    "# Create a dummy last record, so we can get the two months after the end of the data\n",
    "# For example, if Sept 2018 was the last row, create Dec 2018 so resampling will generate\n",
    "# Oct and Nov. Then delete the Dec dummy row\n",
    "lastQ = q.index.values.max()\n",
    "lastQ = pd.to_datetime(lastQ)\n",
    "\n",
    "offset = relativedelta(months=3)\n",
    "nextQ = lastQ + offset\n",
    "\n",
    "q.loc[nextQ] = None   # Create the dummy row\n",
    "\n",
    "# Fill in the months between quarters; use last known value \"ffill\"\n",
    "q = q.resample('M').ffill()\n",
    "q.reset_index(inplace=True)\n",
    "\n",
    "q = q.iloc[:-1]         # Delete the dummy row\n",
    "\n",
    "# \"resample\" for some reason switches the dates to end-of-month; put them back to start-of-month\n",
    "q['Date'] = pd.to_datetime(q['Date']) - MonthBegin(1)\n",
    "\n",
    "q.set_index(\"Date\", inplace=True)\n",
    "\n",
    "for col in q:\n",
    "    tup = (col, \"Q\")\n",
    "    colMapping.append(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the format of the month and sort by month\n",
    "w = pd.read_csv(config[\"dataLoc\"]+\"/Factset/MEIweekly.csv\", parse_dates=True)\n",
    "\n",
    "w[\"Date\"] = pd.to_datetime(w[\"Date\"])\n",
    "\n",
    "w.set_index(\"Date\", inplace=True)\n",
    "w.sort_index(inplace=True)\n",
    "\n",
    "# Group the weeks into months to match the others\n",
    "w = w.resample('M').sum()\n",
    "w.reset_index(inplace=True)\n",
    "\n",
    "# \"resample\" for some reason switches the dates to end-of-month; put them back to start-of-month\n",
    "w['Date'] = pd.to_datetime(w['Date']) - MonthBegin(1)\n",
    "\n",
    "w.set_index(\"Date\", inplace=True)\n",
    "\n",
    "for col in w:\n",
    "    tup = (col, \"W\")\n",
    "    colMapping.append(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the format of the month and sort by month\n",
    "d = pd.read_csv(config[\"dataLoc\"]+\"/Factset/MEIdaily.csv\", parse_dates=True)\n",
    "\n",
    "d[\"Date\"] = pd.to_datetime(d[\"Date\"])\n",
    "\n",
    "d.set_index(\"Date\", inplace=True)\n",
    "d.sort_index(inplace=True)\n",
    "\n",
    "# Group the days into months to match the others\n",
    "d = d.resample('M').last()\n",
    "d.reset_index(inplace=True)\n",
    "\n",
    "# \"resample\" for some reason switches the dates to end-of-month; put them back to start-of-month\n",
    "d['Date'] = pd.to_datetime(d['Date']) - MonthBegin(1)\n",
    "\n",
    "d.set_index(\"Date\", inplace=True)\n",
    "d = d.shift(1)\n",
    "\n",
    "for col in d:\n",
    "    tup = (col, \"D\")\n",
    "    colMapping.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([d,m,w,q], join=\"inner\", axis=1)\n",
    "merged.dropna(inplace=True)\n",
    "\n",
    "merged.to_csv(config[\"dataLoc\"] + \"/Factset/merged.csv\")\n",
    "\n",
    "writeRec(colMapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
