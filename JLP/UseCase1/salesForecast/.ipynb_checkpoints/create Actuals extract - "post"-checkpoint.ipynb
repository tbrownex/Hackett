{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an extract with the Actual sales, by store, for the whole store (OLG aggregated)\n",
    "##### This is for the timeframe after the new layout was put in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = '/home/tbrownex/data/Hackett/JLP/'\n",
    "FILE = 'All_Data_for_10_Treatment_Branches.csv'\n",
    "OLGFILE = \"mapStore-LG.csv\"\n",
    "BS   = \"UseCase1/Banstead/Banstead_summary.csv\"     # Banstead has imputed values (not in the main file)\n",
    "\n",
    "WAVE1  = [\"Twickenham\", \"Thame\", \"Wokingham\", \"Harrogate\"]   # Banstead processed separately\n",
    "WAVE2  = [\"Chandlers Ford\", \"Sidmouth\", \"Barry\", \"Westbury Park\", \"Monmouth\"]\n",
    "WEEKS = {\"wave1\":(\"2017(16)\", \"2017(35)\"),\n",
    "         \"wave2\":(\"2017(22)\", \"2017(35)\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649,291 rows in the master file\n"
     ]
    }
   ],
   "source": [
    "cols = [\"Business Unit Long Name\",\"Trading Week\",\"Layout Group\", \"Line Sales £\"]\n",
    "df = pd.read_csv(PATH+FILE, usecols=cols)\n",
    "print(\"{:,.0f} rows in the master file\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a dictionary mapping Store:OLGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgDict = {}\n",
    "with open(PATH+OLGFILE, \"r\") as mapping:\n",
    "    for rec in mapping:\n",
    "        rec = rec.rstrip()\n",
    "        fields = rec.split(\",\")\n",
    "        lgDict[fields[0]]= fields[1:]   # First entry holds the store; rest are LGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process Wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by Week number\n",
    "df1 = df.loc[(df[\"Trading Week\"] > WEEKS[\"wave1\"][0]) & (df[\"Trading Week\"] < WEEKS[\"wave1\"][1])]\n",
    "\n",
    "# Loop through the stores in the wave\n",
    "dfList = []\n",
    "for store in WAVE1:\n",
    "    tmp = df1.loc[df1[\"Business Unit Long Name\"] == store]\n",
    "    lg = lgDict[store]\n",
    "    tmp = tmp.loc[tmp[\"Layout Group\"].isin(lg)]\n",
    "    dfList.append(tmp)\n",
    "wave1 = pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process Wave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by Week number\n",
    "df2 = df.loc[(df[\"Trading Week\"] > WEEKS[\"wave2\"][0]) & (df[\"Trading Week\"] < WEEKS[\"wave2\"][1])]\n",
    "\n",
    "# Loop through the stores in the wave\n",
    "dfList = []\n",
    "for store in WAVE2:\n",
    "    tmp = df2.loc[df2[\"Business Unit Long Name\"] == store]\n",
    "    lg = lgDict[store]\n",
    "    tmp = tmp.loc[tmp[\"Layout Group\"].isin(lg)]\n",
    "    dfList.append(tmp)\n",
    "wave2 = pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2 waves\n",
    "combined = pd.concat([wave1,wave2])\n",
    "\n",
    "# Get the aggregated sales by LG\n",
    "summary = combined.groupby([\"Business Unit Long Name\", \"Trading Week\"])[\"Line Sales £\"].sum()\n",
    "\n",
    "summary = summary.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Banstead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = pd.read_csv(PATH+BS)\n",
    "\n",
    "# Add the name of the store and remove the actual (to match format of \"summary\")\n",
    "bs[\"Line Sales £\"] = bs[\"Line Sales - imputed\"]\n",
    "del bs[\"Line Sales - imputed\"]\n",
    "\n",
    "bs[\"Business Unit Long Name\"] = \"Banstead\"\n",
    "\n",
    "# Reorder the columns, again to match \"summary\"\n",
    "cols = [\"Business Unit Long Name\", \"Trading Week\", \"Line Sales £\"]\n",
    "bs = bs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([summary, bs])\n",
    "\n",
    "final.to_csv(PATH+\"/UseCase1/salesForecast/store_sales_by_OLG-post.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
